{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 956177,
          "sourceType": "datasetVersion",
          "datasetId": 519884
        },
        {
          "sourceId": 6945939,
          "sourceType": "datasetVersion",
          "datasetId": 3989137
        },
        {
          "sourceId": 7615428,
          "sourceType": "datasetVersion",
          "datasetId": 4434986
        },
        {
          "sourceId": 9146200,
          "sourceType": "datasetVersion",
          "datasetId": 5524489
        },
        {
          "sourceId": 9971597,
          "sourceType": "datasetVersion",
          "datasetId": 6134770
        }
      ],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Deepfake Detection Notebook",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anchal2611/Cry-Compass/blob/main/Deepfake_Detection_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "greatgamedota_faceforensics_path = kagglehub.dataset_download('greatgamedota/faceforensics')\n",
        "nanduncs_1000_videos_split_path = kagglehub.dataset_download('nanduncs/1000-videos-split')\n",
        "hungle3401_faceforensics_path = kagglehub.dataset_download('hungle3401/faceforensics')\n",
        "sanikatiwarekar_deep_fake_detection_dfd_entire_original_dataset_path = kagglehub.dataset_download('sanikatiwarekar/deep-fake-detection-dfd-entire-original-dataset')\n",
        "chandashekar8_deepfake_testing_videos_path = kagglehub.dataset_download('chandashekar8/deepfake-testing-videos')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "MTg70JQ8xj2r"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-20T19:47:28.785268Z",
          "iopub.execute_input": "2025-08-20T19:47:28.78559Z",
          "iopub.status.idle": "2025-08-20T19:48:11.726486Z",
          "shell.execute_reply.started": "2025-08-20T19:47:28.785555Z",
          "shell.execute_reply": "2025-08-20T19:48:11.725618Z"
        },
        "id": "He4Xd_ncxj2s"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA PREPARATION"
      ],
      "metadata": {
        "id": "YbHlCNoXxj2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow opencv-python tqdm scikit-learn matplotlib seaborn mtcnn"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-20T19:48:11.728196Z",
          "iopub.execute_input": "2025-08-20T19:48:11.728473Z",
          "iopub.status.idle": "2025-08-20T19:48:15.555002Z",
          "shell.execute_reply.started": "2025-08-20T19:48:11.728455Z",
          "shell.execute_reply": "2025-08-20T19:48:15.553988Z"
        },
        "id": "fylBDlDYxj2t"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preparation\n",
        "!pip install tensorflow opencv-python tqdm scikit-learn matplotlib seaborn mtcnn lz4  # Added lz4\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from mtcnn import MTCNN\n",
        "\n",
        "# Paths to FF++ data in Kaggle\n",
        "REAL_PATH = \"/kaggle/input/faceforensics/FF++/real\"\n",
        "FAKE_PATH = \"/kaggle/input/faceforensics/FF++/fake\"\n",
        "OUTPUT_FRAME_SIZE = (128, 128)  # Reduced size for memory efficiency\n",
        "FRAME_COUNT = 10  # Frames per video\n",
        "MAX_VIDEOS = 200  # Reduced to 200 per class to manage memory (adjust as needed)\n",
        "\n",
        "# Verify dataset availability\n",
        "if not os.path.exists(REAL_PATH) or not os.path.exists(FAKE_PATH):\n",
        "    raise FileNotFoundError(f\"Dataset paths not found: REAL_PATH={REAL_PATH}, FAKE_PATH={FAKE_PATH}. Please add the FaceForensics++ dataset.\")\n",
        "\n",
        "detector = MTCNN()\n",
        "\n",
        "def extract_face(frame):\n",
        "    results = detector.detect_faces(frame)\n",
        "    if results:\n",
        "        x, y, w, h = results[0]['box']\n",
        "        x, y = max(0, x), max(0, y)\n",
        "        face = frame[y:y+h, x:x+w]\n",
        "        return cv2.resize(face, OUTPUT_FRAME_SIZE)\n",
        "    return cv2.resize(frame, OUTPUT_FRAME_SIZE)  # Fallback if no face detected\n",
        "\n",
        "def extract_frames(video_path, output_size=(128, 128), frame_count=10):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Warning: Could not open video file {video_path}, skipping.\")\n",
        "        return np.array([])\n",
        "    frames = []\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    step = max(total_frames // frame_count, 1)\n",
        "    for i in range(frame_count):\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, i * step)\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame = extract_face(frame)\n",
        "        frames.append(frame)\n",
        "    cap.release()\n",
        "    return np.array(frames) if len(frames) > 0 else np.zeros((frame_count, output_size[0], output_size[1], 3), dtype=np.uint8)\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "print(\"Processing real videos...\")\n",
        "real_videos = os.listdir(REAL_PATH)[:MAX_VIDEOS]\n",
        "for video_file in tqdm(real_videos):\n",
        "    video_path = os.path.join(REAL_PATH, video_file)\n",
        "    frames = extract_frames(video_path, output_size=OUTPUT_FRAME_SIZE, frame_count=FRAME_COUNT)\n",
        "    if len(frames) == FRAME_COUNT:\n",
        "        data.append(frames)\n",
        "        labels.append(0)  # 0 for real\n",
        "\n",
        "print(\"Processing fake videos...\")\n",
        "fake_videos = os.listdir(FAKE_PATH)[:MAX_VIDEOS]\n",
        "for video_file in tqdm(fake_videos):\n",
        "    video_path = os.path.join(FAKE_PATH, video_file)\n",
        "    frames = extract_frames(video_path, output_size=OUTPUT_FRAME_SIZE, frame_count=FRAME_COUNT)\n",
        "    if len(frames) == FRAME_COUNT:\n",
        "        data.append(frames)\n",
        "        labels.append(1)  # 1 for fake\n",
        "\n",
        "if len(data) == 0:\n",
        "    raise ValueError(\"No valid frames extracted. Check dataset or reduce MAX_VIDEOS/FRAME_COUNT.\")\n",
        "\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Split into train, validation, and test sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Normalize pixel values\n",
        "X_train = X_train / 255.0\n",
        "X_val = X_val / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Convert labels to categorical\n",
        "y_train = to_categorical(y_train, num_classes=2)\n",
        "y_val = to_categorical(y_val, num_classes=2)\n",
        "y_test = to_categorical(y_test, num_classes=2)\n",
        "\n",
        "print(f\"Data shapes: Train - {X_train.shape}, Val - {X_val.shape}, Test - {X_test.shape}\")\n",
        "\n",
        "# Save to avoid recomputing\n",
        "np.save('/kaggle/working/X_train.npy', X_train)\n",
        "np.save('/kaggle/working/y_train.npy', y_train)\n",
        "np.save('/kaggle/working/X_val.npy', X_val)\n",
        "np.save('/kaggle/working/y_val.npy', y_val)\n",
        "np.save('/kaggle/working/X_test.npy', X_test)\n",
        "np.save('/kaggle/working/y_test.npy', y_test)\n",
        "\n",
        "# Verify saved files\n",
        "!ls -lh /kaggle/working/"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-20T19:48:15.556159Z",
          "iopub.execute_input": "2025-08-20T19:48:15.556411Z",
          "iopub.status.idle": "2025-08-20T22:03:28.548809Z",
          "shell.execute_reply.started": "2025-08-20T19:48:15.556386Z",
          "shell.execute_reply": "2025-08-20T22:03:28.547946Z"
        },
        "id": "CqKeV914xj2u"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA AUGMENTATION"
      ],
      "metadata": {
        "id": "I9SO5ZEzxj2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=40,\n",
        "    zoom_range=0.4,\n",
        "    brightness_range=[0.5, 1.5],\n",
        "    shear_range=0.4,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    channel_shift_range=10.0,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "def augment_frames(frames):\n",
        "    augmented_frames = []\n",
        "    for frame in frames:\n",
        "        frame = datagen.random_transform(frame)\n",
        "        augmented_frames.append(frame)\n",
        "    return np.array(augmented_frames)\n",
        "\n",
        "augmented_data = []\n",
        "augmented_labels = []\n",
        "\n",
        "for i in tqdm(range(len(X_train))):\n",
        "    augmented_frames = augment_frames(X_train[i])\n",
        "    augmented_data.append(augmented_frames)\n",
        "    augmented_labels.append(y_train[i])\n",
        "\n",
        "X_train_augmented = np.concatenate((X_train, np.array(augmented_data)))\n",
        "y_train_augmented = np.concatenate((y_train, np.array(augmented_labels)))\n",
        "\n",
        "print(f\"Augmented Train Data: {X_train_augmented.shape}\")\n",
        "np.save('/kaggle/working/X_train_augmented.npy', X_train_augmented)\n",
        "np.save('/kaggle/working/y_train_augmented.npy', y_train_augmented)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-20T22:03:28.550132Z",
          "iopub.execute_input": "2025-08-20T22:03:28.550461Z",
          "iopub.status.idle": "2025-08-20T22:03:48.293681Z",
          "shell.execute_reply.started": "2025-08-20T22:03:28.550431Z",
          "shell.execute_reply": "2025-08-20T22:03:48.292858Z"
        },
        "id": "A6wuCnqbxj2v"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL ARCHITECTURE"
      ],
      "metadata": {
        "id": "6kP72Jxpxj2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, TimeDistributed, Bidirectional, GRU, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "def build_best_model(input_shape=(FRAME_COUNT, 128, 128, 3)):\n",
        "    base_model = Xception(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "    base_model.trainable = True\n",
        "    for layer in base_model.layers[:-30]:  # Unfreeze last 30 layers for fine-tuning\n",
        "        layer.trainable = False\n",
        "\n",
        "    model = Sequential([\n",
        "        TimeDistributed(base_model),\n",
        "        TimeDistributed(GlobalAveragePooling2D()),\n",
        "        BatchNormalization(),\n",
        "        Bidirectional(GRU(128, return_sequences=False, kernel_regularizer=l2(0.005))),\n",
        "        Dropout(0.5),\n",
        "        Dense(64, activation='relu', kernel_regularizer=l2(0.005)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(2, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001, clipnorm=1.0),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = build_best_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-20T22:03:48.297582Z",
          "iopub.execute_input": "2025-08-20T22:03:48.297835Z",
          "iopub.status.idle": "2025-08-20T22:03:49.400033Z",
          "shell.execute_reply.started": "2025-08-20T22:03:48.297817Z",
          "shell.execute_reply": "2025-08-20T22:03:49.399178Z"
        },
        "id": "VwZHrRpWxj2w"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL TRAINING"
      ],
      "metadata": {
        "id": "UFhw7mz9xj2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "# Compute class weights for balance\n",
        "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(np.argmax(y_train, axis=1)), y=np.argmax(y_train, axis=1))\n",
        "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
        "\n",
        "# Place ModelCheckpoint here\n",
        "checkpoint = ModelCheckpoint(\n",
        "    \"/kaggle/working/deepfake_detection_model.keras\",\n",
        "    monitor=\"val_accuracy\",\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.5,\n",
        "    patience=5,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor=\"val_accuracy\",\n",
        "    patience=20,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train_augmented, y_train_augmented,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=50,  # Reduced for testing, adjust to 100 if needed\n",
        "    batch_size=8,\n",
        "    class_weight=class_weight_dict,\n",
        "    callbacks=[checkpoint, lr_scheduler, early_stopping]\n",
        ")\n",
        "\n",
        "# Place model.save() here\n",
        "model.save(\"/kaggle/working/deepfake_detection_model_final.keras\")\n",
        "\n",
        "# Verify saved files\n",
        "!ls -lh /kaggle/working/"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-20T22:03:49.401079Z",
          "iopub.execute_input": "2025-08-20T22:03:49.401424Z",
          "iopub.status.idle": "2025-08-20T22:15:22.422883Z",
          "shell.execute_reply.started": "2025-08-20T22:03:49.401389Z",
          "shell.execute_reply": "2025-08-20T22:15:22.421978Z"
        },
        "id": "Mq0qzHvHxj2x"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL TESTING"
      ],
      "metadata": {
        "id": "0V4Y4c-Pxj2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "model = load_model('/kaggle/working/deepfake_detection_model.keras')\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred_classes)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred_classes, target_names=['REAL', 'FAKE']))\n",
        "\n",
        "def plot_training_history(history):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_confusion_matrix(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true = np.argmax(y_test, axis=1)\n",
        "    cm = confusion_matrix(y_true, y_pred_classes)\n",
        "    cm_labels = ['Real', 'Fake']\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=cm_labels, yticklabels=cm_labels)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.show()\n",
        "    print(classification_report(y_true, y_pred_classes, target_names=cm_labels))\n",
        "\n",
        "plot_training_history(history)\n",
        "plot_confusion_matrix(model, X_test, y_test)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-20T22:15:22.424354Z",
          "iopub.execute_input": "2025-08-20T22:15:22.424666Z",
          "iopub.status.idle": "2025-08-20T22:16:02.603242Z",
          "shell.execute_reply.started": "2025-08-20T22:15:22.424639Z",
          "shell.execute_reply": "2025-08-20T22:16:02.602464Z"
        },
        "id": "IRmkGGjjxj2x"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# REAL TIME DETECTION"
      ],
      "metadata": {
        "id": "6WP8DNZDxj2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Real-Time Detection\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Function to extract frames from a video\n",
        "def extract_frames(video_path, output_size=(128, 128), frame_count=10):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Could not open video file {video_path}\")\n",
        "        return np.array([])  # Return empty array if video fails to open\n",
        "    frames = []\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    step = max(total_frames // frame_count, 1)  # Uniform sampling\n",
        "\n",
        "    for i in range(frame_count):\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, i * step)\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame = cv2.resize(frame, output_size)  # Resize frame\n",
        "        frames.append(frame)\n",
        "    cap.release()\n",
        "\n",
        "    # Convert to NumPy array and ensure 4D shape\n",
        "    if len(frames) == 0:\n",
        "        print(f\"Warning: No frames extracted from {video_path}\")\n",
        "        return np.zeros((0, output_size[0], output_size[1], 3), dtype=np.uint8)\n",
        "    return np.array(frames, dtype=np.uint8)\n",
        "\n",
        "# Function to predict video\n",
        "def predict_video(video_path, model, output_size=(128, 128), frame_count=10):\n",
        "    frames = extract_frames(video_path, output_size, frame_count)\n",
        "    if len(frames) == 0:\n",
        "        print(f\"Error: No frames to predict for {video_path}\")\n",
        "        return\n",
        "\n",
        "    # Ensure frames is 4D\n",
        "    if len(frames.shape) == 3:  # (height, width, channels)\n",
        "        frames = np.expand_dims(frames, axis=0)  # Make it (1, height, width, channels)\n",
        "    elif len(frames.shape) == 4 and frames.shape[0] < frame_count:\n",
        "        pad_length = frame_count - frames.shape[0]\n",
        "        pad_width = [(0, pad_length)] + [(0, 0) for _ in range(len(frames.shape) - 1)]\n",
        "        frames = np.pad(frames, pad_width, mode='constant', constant_values=0)\n",
        "    elif len(frames.shape) != 4:\n",
        "        print(f\"Error: Unexpected frame shape {frames.shape} for {video_path}\")\n",
        "        return\n",
        "\n",
        "    frames = frames / 255.0  # Normalize\n",
        "    frames = np.expand_dims(frames, axis=0)  # Add batch dimension\n",
        "    prediction = model.predict(frames)\n",
        "    label = \"FAKE\" if np.argmax(prediction) == 1 else \"REAL\"\n",
        "    confidence = float(prediction[0][np.argmax(prediction)])\n",
        "    print(f\"Prediction: {label} (Confidence: {confidence:.2f})\")\n",
        "\n",
        "# Load the model with file existence check\n",
        "model_path = '/kaggle/working/deepfake_detection_model.keras'\n",
        "if os.path.exists(model_path):\n",
        "    loaded_model = load_model(model_path)\n",
        "    print(f\"Model loaded successfully from {model_path}\")\n",
        "else:\n",
        "    print(f\"Error: Model file not found at {model_path}. Please run the training section first.\")\n",
        "    raise FileNotFoundError(f\"Model file not found at {model_path}\")\n",
        "\n",
        "# Use the same dataset paths as data loading\n",
        "REAL_PATH = \"/kaggle/input/faceforensics/FF++/real\"\n",
        "FAKE_PATH = \"/kaggle/input/faceforensics/FF++/fake\"\n",
        "\n",
        "# Get the first available video files (verify they exist)\n",
        "real_videos = os.listdir(REAL_PATH)\n",
        "fake_videos = os.listdir(FAKE_PATH)\n",
        "if not real_videos or not fake_videos:\n",
        "    print(\"Error: No video files found in REAL_PATH or FAKE_PATH. Check dataset input.\")\n",
        "else:\n",
        "    real_sample_path = os.path.join(REAL_PATH, real_videos[0])  # First real video\n",
        "    fake_sample_path = os.path.join(FAKE_PATH, fake_videos[0])  # First fake video\n",
        "\n",
        "    # Test predictions\n",
        "    print(\"Real Video Prediction:\")\n",
        "    predict_video(real_sample_path, loaded_model)\n",
        "\n",
        "    print(\"Fake Video Prediction:\")\n",
        "    predict_video(fake_sample_path, loaded_model)\n",
        "\n",
        "# List contents of /kaggle/working/ to verify model or other files\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-20T22:16:02.604328Z",
          "iopub.execute_input": "2025-08-20T22:16:02.60466Z",
          "iopub.status.idle": "2025-08-20T22:16:27.193613Z",
          "shell.execute_reply.started": "2025-08-20T22:16:02.604629Z",
          "shell.execute_reply": "2025-08-20T22:16:27.193Z"
        },
        "id": "8OrN_eBoxj2y"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /kaggle/working/"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-20T22:16:27.194711Z",
          "iopub.execute_input": "2025-08-20T22:16:27.195002Z",
          "iopub.status.idle": "2025-08-20T22:16:27.479416Z",
          "shell.execute_reply.started": "2025-08-20T22:16:27.194977Z",
          "shell.execute_reply": "2025-08-20T22:16:27.478563Z"
        },
        "id": "cTO3ucnxxj2y"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /kaggle/working/deepfake_detection_model.keras"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-20T22:16:27.487315Z",
          "iopub.execute_input": "2025-08-20T22:16:27.487586Z",
          "iopub.status.idle": "2025-08-20T22:16:27.762149Z",
          "shell.execute_reply.started": "2025-08-20T22:16:27.48756Z",
          "shell.execute_reply": "2025-08-20T22:16:27.761243Z"
        },
        "id": "N2HuIL9jxj2y"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UI CODE"
      ],
      "metadata": {
        "id": "K4KYemN-xj2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import customtkinter as ctk\n",
        "from tkinter import filedialog, messagebox\n",
        "from tensorflow.keras.models import load_model\n",
        "from mtcnn import MTCNN\n",
        "from PIL import Image, ImageTk\n",
        "import csv\n",
        "\n",
        "# ---------------------------\n",
        "# PARAMETERS\n",
        "# ---------------------------\n",
        "OUTPUT_FRAME_SIZE = (128, 128)\n",
        "FRAME_COUNT = 10\n",
        "MODEL_PATH = \"deepfake_detection_model.keras\"\n",
        "FEEDBACK_FILE = \"feedback_log.csv\"\n",
        "\n",
        "detector = MTCNN()\n",
        "\n",
        "# ---------------------------\n",
        "# FACE + FRAME EXTRACTION\n",
        "# ---------------------------\n",
        "def extract_face(frame):\n",
        "    results = detector.detect_faces(frame)\n",
        "    if results:\n",
        "        x, y, w, h = results[0]['box']\n",
        "        x, y = max(0, x), max(0, y)\n",
        "        face = frame[y:y + h, x:x + w]\n",
        "        return cv2.resize(face, OUTPUT_FRAME_SIZE)\n",
        "    return cv2.resize(frame, OUTPUT_FRAME_SIZE)\n",
        "\n",
        "def extract_frames(video_path, frame_count=FRAME_COUNT, output_size=OUTPUT_FRAME_SIZE):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        return np.array([])\n",
        "    frames = []\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    step = max(total_frames // frame_count, 1)\n",
        "    for i in range(frame_count):\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, i * step)\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame = extract_face(frame)\n",
        "        frames.append(frame)\n",
        "    cap.release()\n",
        "    return np.array(frames) if len(frames) > 0 else np.zeros(\n",
        "        (frame_count, output_size[0], output_size[1], 3), dtype=np.uint8\n",
        "    )\n",
        "\n",
        "# ---------------------------\n",
        "# LOAD TRAINED MODEL\n",
        "# ---------------------------\n",
        "if os.path.exists(MODEL_PATH):\n",
        "    model = load_model(MODEL_PATH)\n",
        "    print(\"‚úÖ Model loaded successfully!\")\n",
        "else:\n",
        "    raise FileNotFoundError(f\"‚ùå Model not found: {MODEL_PATH}\")\n",
        "\n",
        "# ---------------------------\n",
        "# PREDICTION FUNCTION\n",
        "# ---------------------------\n",
        "def predict_video(video_path):\n",
        "    frames = extract_frames(video_path)\n",
        "    if frames.shape[0] != FRAME_COUNT:\n",
        "        return \"Error\"\n",
        "    frames = frames / 255.0\n",
        "    frames = np.expand_dims(frames, axis=0)\n",
        "    prediction = model.predict(frames, verbose=0)\n",
        "    class_idx = np.argmax(prediction, axis=1)[0]\n",
        "    return \"Real\" if class_idx == 0 else \"Deepfake\"\n",
        "\n",
        "# ---------------------------\n",
        "# FEEDBACK SAVE FUNCTION\n",
        "# ---------------------------\n",
        "def save_feedback(video_path, model_prediction, user_feedback):\n",
        "    file_exists = os.path.isfile(FEEDBACK_FILE)\n",
        "    with open(FEEDBACK_FILE, mode=\"a\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        if not file_exists:\n",
        "            writer.writerow([\"Video\", \"Prediction\", \"UserFeedback\"])\n",
        "        writer.writerow([os.path.basename(video_path), model_prediction, user_feedback])\n",
        "    print(f\"üíæ Feedback saved: {user_feedback}\")\n",
        "\n",
        "# ---------------------------\n",
        "# MODERN GUI (CTk)\n",
        "# ---------------------------\n",
        "class DeepfakeDetectorApp(ctk.CTk):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.title(\"üé≠ Deepfake Detector\")\n",
        "        self.geometry(\"750x600\")\n",
        "        ctk.set_appearance_mode(\"dark\")\n",
        "        ctk.set_default_color_theme(\"blue\")\n",
        "\n",
        "        self.video_path = None\n",
        "        self.prediction_result = None\n",
        "\n",
        "        # Title\n",
        "        self.title_label = ctk.CTkLabel(\n",
        "            self, text=\"AI Deepfake Detector\",\n",
        "            font=(\"Poppins Bold\", 28), text_color=\"white\"\n",
        "        )\n",
        "        self.title_label.pack(pady=20)\n",
        "\n",
        "        # Upload Button\n",
        "        self.upload_btn = ctk.CTkButton(\n",
        "            self, text=\"üìÇ Upload Video\",\n",
        "            command=self.upload_video,\n",
        "            font=(\"Poppins\", 18),\n",
        "            width=220, height=50, corner_radius=15\n",
        "        )\n",
        "        self.upload_btn.pack(pady=20)\n",
        "\n",
        "        # Progress Bar\n",
        "        self.progress = ctk.CTkProgressBar(self, width=400)\n",
        "        self.progress.pack(pady=10)\n",
        "        self.progress.set(0)\n",
        "\n",
        "        # Preview Frame\n",
        "        self.preview_label = ctk.CTkLabel(self, text=\"\", width=400, height=200)\n",
        "        self.preview_label.pack(pady=15)\n",
        "\n",
        "        # Result Stamp\n",
        "        self.result_label = ctk.CTkLabel(\n",
        "            self, text=\"\", font=(\"Poppins Bold\", 26),\n",
        "            text_color=\"white\"\n",
        "        )\n",
        "        self.result_label.pack(pady=25)\n",
        "\n",
        "        # Feedback Buttons (Initially hidden)\n",
        "        self.feedback_frame = ctk.CTkFrame(self)\n",
        "        self.correct_btn = ctk.CTkButton(\n",
        "            self.feedback_frame, text=\"üëç Correct\",\n",
        "            fg_color=\"#4CAF50\", hover_color=\"#388E3C\",\n",
        "            command=lambda: self.save_user_feedback(\"Correct\")\n",
        "        )\n",
        "        self.wrong_btn = ctk.CTkButton(\n",
        "            self.feedback_frame, text=\"üëé Wrong\",\n",
        "            fg_color=\"#FF5252\", hover_color=\"#D32F2F\",\n",
        "            command=lambda: self.save_user_feedback(\"Wrong\")\n",
        "        )\n",
        "        self.correct_btn.pack(side=\"left\", padx=20, pady=10)\n",
        "        self.wrong_btn.pack(side=\"left\", padx=20, pady=10)\n",
        "\n",
        "        # Status Bar\n",
        "        self.status_label = ctk.CTkLabel(\n",
        "            self, text=\"Ready\", font=(\"Poppins\", 14),\n",
        "            text_color=\"gray\"\n",
        "        )\n",
        "        self.status_label.pack(side=\"bottom\", pady=10)\n",
        "\n",
        "    def upload_video(self):\n",
        "        file_path = filedialog.askopenfilename(\n",
        "            title=\"Select a video\",\n",
        "            filetypes=[(\"Video files\", \"*.mp4 *.avi *.mov *.mkv\")]\n",
        "        )\n",
        "        if file_path:\n",
        "            self.video_path = file_path\n",
        "            try:\n",
        "                self.progress.set(0.3)\n",
        "                self.status_label.configure(text=\"Processing video...\")\n",
        "\n",
        "                # Show first frame as preview\n",
        "                cap = cv2.VideoCapture(file_path)\n",
        "                ret, frame = cap.read()\n",
        "                cap.release()\n",
        "                if ret:\n",
        "                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                    img = Image.fromarray(frame_rgb)\n",
        "                    img.thumbnail((400, 200))\n",
        "                    imgtk = ImageTk.PhotoImage(img)\n",
        "                    self.preview_label.configure(image=imgtk)\n",
        "                    self.preview_label.image = imgtk\n",
        "\n",
        "                # Prediction\n",
        "                self.progress.set(0.7)\n",
        "                result = predict_video(file_path)\n",
        "                self.prediction_result = result\n",
        "\n",
        "                if result == \"Real\":\n",
        "                    self.result_label.configure(\n",
        "                        text=\"‚úÖ REAL VIDEO\",\n",
        "                        text_color=\"#4CAF50\"\n",
        "                    )\n",
        "                else:\n",
        "                    self.result_label.configure(\n",
        "                        text=\"‚ùå DEEPFAKE DETECTED\",\n",
        "                        text_color=\"#FF5252\"\n",
        "                    )\n",
        "\n",
        "                # Show feedback options\n",
        "                self.feedback_frame.pack(pady=10)\n",
        "                self.progress.set(1.0)\n",
        "                self.status_label.configure(text=\"Done\")\n",
        "\n",
        "            except Exception as e:\n",
        "                messagebox.showerror(\"Error\", f\"Failed:\\n{e}\")\n",
        "                self.status_label.configure(text=\"Error\")\n",
        "\n",
        "    def save_user_feedback(self, feedback):\n",
        "        if self.video_path and self.prediction_result:\n",
        "            save_feedback(self.video_path, self.prediction_result, feedback)\n",
        "            messagebox.showinfo(\"Feedback\", \"‚úÖ Thanks for your feedback!\")\n",
        "            self.status_label.configure(text=\"Feedback submitted\")\n",
        "            # Hide feedback buttons after submission\n",
        "            self.feedback_frame.pack_forget()\n",
        "\n",
        "# ---------------------------\n",
        "# ENTRY POINT\n",
        "# ---------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    app = DeepfakeDetectorApp()\n",
        "    app.mainloop()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-20T22:16:27.763582Z",
          "iopub.execute_input": "2025-08-20T22:16:27.763904Z",
          "iopub.status.idle": "2025-08-20T22:16:29.937983Z",
          "shell.execute_reply.started": "2025-08-20T22:16:27.763878Z",
          "shell.execute_reply": "2025-08-20T22:16:29.936951Z"
        },
        "id": "CzI3sJwDxj2z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MADE BY : ANCHAL GUPTA"
      ],
      "metadata": {
        "id": "NQp3sxIRxj2z"
      }
    }
  ]
}